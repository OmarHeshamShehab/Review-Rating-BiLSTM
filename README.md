# Review-Rating-BiLSTM

A fullyâ€“reproducible deep-learning pipeline for predicting **1â€“10 star ratings** from free-form movie reviews.  
The project was developed as part of the *Dev-Acad NLP* challenge and demonstrates modern naturalâ€‘languageâ€‘processing (NLP) techniques with TensorFlowÂ 2/Keras, spaCy and Scikitâ€‘Learn.

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **Automatic data rebuild** | The `data/` folder is *not* version-controlled. If it is missing, the notebook zips the raw `dev-acad-nlp` corpus and recreates the same structure on the fly. |
| **Lightweight preprocessing** | Tokenisation, stopâ€‘word removal & lemmatisation via *spaCy `en_core_web_sm`*. |
| **Deep Biâ€‘LSTM architecture** | Two stacked bidirectional LSTM layers capture longâ€‘range context in both directions. |
| **Robust training utilities** | Early Stopping and Reduceâ€‘LRâ€‘onâ€‘Plateau callbacks prevent overâ€‘fitting. |
| **Singleâ€‘command submission** | Generates a readyâ€‘toâ€‘upload `submission.csv` that meets the competition format. |

---

## ğŸ—‚ï¸ Project Structure

```text
.
â”œâ”€â”€ LSTM_Text_Classification.ipynb   # Endâ€‘toâ€‘end workflow
â”œâ”€â”€ dev-acad-nlp.zip                # Raw corpus (11â€¯k train + 3â€¯k test)
â”œâ”€â”€ data/                           # Autoâ€‘generated working directory
â”‚   â”œâ”€â”€ train/ trainXXXX.txt        # Cleaned review texts (Latinâ€‘1)
â”‚   â”œâ”€â”€ test/  testXXXX.txt
â”‚   â””â”€â”€ labels_train.csv            # ReviewID,Rating (1â€“10)
â””â”€â”€ submission.csv                  # Sample or model output
```

> **Note**  
> You never commit `data/`. Any fresh clone only needs `dev-acad-nlp.zip`; the notebook will unzip it the first time it runs.

---

## ğŸ—ï¸ Model Architecture

```
Input â†’ Embedding (30â€¯k vocab, 128â€¯d)
      â†’ Biâ€‘LSTM (64 units, return_sequences)
      â†’ Biâ€‘LSTM (32 units) 
      â†’ DropoutÂ 0.5
      â†’ DenseÂ 32Â ReLU
      â†’ DropoutÂ 0.3
      â†’ DenseÂ 10Â Softmax â†’ RatingÂ (1â€‘10)
```

* **Loss** : `sparse_categorical_crossentropy`  
* **Optimiser** : `Adam`  
* **Metrics** : Accuracy

---

## ğŸš€ Quickâ€‘start

```bash
# Clone repo
git clone https://github.com/YOUR-ORG/Review-Rating-BiLSTM.git
cd Review-Rating-BiLSTM

# Create environment
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# (Optional) place dev-acad-nlp.zip in project root
# Run the notebook
jupyter lab LSTM_Text_Classification.ipynb
```

The notebook will:

1. Unzip *dev-acad-nlp* âœ `data/`  
2. Clean & lemmatise texts  
3. Train/validate the Biâ€‘LSTM (80â€¯/â€¯20 split)  
4. Predict ratings for the hidden test set  
5. Save `submission.csv`

---

## ğŸ“Š Reproducing the baseline score

With the default hyperâ€‘parameters the notebook achieves **~0.48 macro accuracy** on the heldâ€‘out validation set (exact numbers may vary due to random seeds and GPU). Feel free to tweak:

* `MAX_NUM_WORDS` â€“ vocabulary size  
* `EMBEDDING_DIM` â€“ embedding dimension  
* LSTM units / layers  
* Dropout rates & batch size  
* Learningâ€‘rate schedule

---

## ğŸ“ Requirements

* PythonÂ â‰¥Â 3.9  
* TensorFlowÂ 2.15  
* spaCyÂ â‰¥Â 3.7  
* matplotlib, seaborn, scikitâ€‘learn, pandas, numpy

A full `requirements.txt` is provided.

---

## ğŸ¤ Contributing

Pull requests are welcome! Please open an issue first to discuss major changes.

1. Fork the repo & create a branch `feat/my-awesome-improvement`  
2. Commit with conventional messages  
3. Ensure the unit tests/notebook still run  
4. Submit a PRÂ ğŸ‰

---

## ğŸªª License

Distributed under the **MIT License**. See [`LICENSE`](LICENSE) for details.

---

## ğŸ™ Acknowledgements

* **Dev-Acad** for releasing the dataset.  
* *spaCy* & *TensorFlow* teams for their brilliant libraries.  
* Inspired by myriad Kaggle kernels on text classification.

---

<div align="center">

_â€œTalk is cheap. Show me the data.â€_  
â€” *Linus Torvalds*

</div>
